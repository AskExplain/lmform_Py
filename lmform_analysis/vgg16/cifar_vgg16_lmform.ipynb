{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1c7f38-3c47-4931-b00a-23be98669812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def lmform(\n",
    "    data_list,\n",
    "    config,\n",
    "    join,\n",
    "    transfer=None):\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    np.random.seed(seed=config[\"seed\"])\n",
    "    \n",
    "    convergence_parameters = {}\n",
    "    convergence_parameters[\"count\"] = 0\n",
    "    convergence_parameters[\"score_vec\"] = [10e6]\n",
    "    \n",
    "    main_parameters, main_code = initialise_lmform(data_list = data_list,\n",
    "                                         config = config,\n",
    "                                         join = join,\n",
    "                                         transfer = transfer\n",
    "                                        )\n",
    "    \n",
    "    if (config[\"verbose\"]):\n",
    "            print(\"Beginning lmform learning with:    Sample dimension reduction (config[i_dim]): \" + str( config[\"i_dim\"] ) + \"    Feature dimension reduction (config[j_dim]): \" + str( config[\"j_dim\"] ) + \"    Tolerance Threshold: \" + str( config[\"tol\"] ) + \"   Maximum number of iterations: \"  + str( config[\"max_iter\"] ) + \"   Verbose: \", config[\"verbose\"])\n",
    "\n",
    "            \n",
    "    while True:\n",
    "        prev_encode = main_code[\"encode\"]\n",
    "        \n",
    "        for i in range(len(join[\"complete\"][\"data_list\"])):\n",
    "            internal_parameters = {}\n",
    "            internal_parameters[\"beta\"] = main_parameters[\"beta\"][join[\"complete\"][\"beta\"][i]]\n",
    "            internal_parameters[\"intercept\"] = main_parameters[\"intercept\"][join[\"complete\"][\"data_list\"][i]]\n",
    "            \n",
    "            internal_code = {}\n",
    "            internal_code[\"encode\"] = main_code[\"encode\"][join[\"complete\"][\"code\"][i]]\n",
    "            internal_code[\"code\"] = main_code[\"code\"][join[\"complete\"][\"code\"][i]]\n",
    "            \n",
    "            return_parameters, return_code  = update_set_lmform( \n",
    "                                        x = data_list[join[\"complete\"][\"data_list\"][i]],\n",
    "                                        main_parameters = internal_parameters,\n",
    "                                        main_code = internal_code,\n",
    "                                        config = config,\n",
    "                                        fix = transfer[\"fix\"]\n",
    "                                        )\n",
    "\n",
    "            main_parameters[\"beta\"][join[\"complete\"][\"beta\"][i]] = internal_parameters[\"beta\"]\n",
    "            main_parameters[\"intercept\"][join[\"complete\"][\"data_list\"][i]] = internal_parameters[\"intercept\"]\n",
    "            \n",
    "            main_code[\"code\"][join[\"complete\"][\"code\"][i]] = internal_code[\"code\"]\n",
    "            main_code[\"encode\"][join[\"complete\"][\"code\"][i]] = internal_code[\"encode\"]\n",
    "            \n",
    "        total_mae = 0\n",
    "        for X in range(len(join[\"complete\"][\"data_list\"])):      \n",
    "            total_mae += torch.mean(torch.abs(main_code[\"encode\"][join[\"complete\"][\"code\"][X]] - prev_encode[join[\"complete\"][\"code\"][X]]))\n",
    "\n",
    "        # Check convergence\n",
    "        convergence_parameters[\"score_vec\"] += [total_mae]\n",
    "        MSE = convergence_parameters[\"score_vec\"][-1]\n",
    "        prev_MSE = convergence_parameters[\"score_vec\"][-2]\n",
    "        \n",
    "        if convergence_parameters[\"count\"]>=1:\n",
    "            if config[\"verbose\"]:\n",
    "                print(\"Iteration:   \"+str(convergence_parameters[\"count\"])+\"   with Tolerance of:   \"+str(abs(prev_MSE - MSE)))\n",
    "            if convergence_parameters[\"count\"] >= config[\"max_iter\"]:\n",
    "                break\n",
    "            if abs(prev_MSE - MSE) < config[\"tol\"]:\n",
    "                break\n",
    "        convergence_parameters[\"count\"] += 1\n",
    "\n",
    "    if (config[\"verbose\"]):\n",
    "        print(\"Learning has converged for lmform, beginning (if requested) dimension reduction\")\n",
    "\n",
    "    return_data = {}\n",
    "    return_data[\"main_parameters\"] = main_parameters\n",
    "    return_data[\"main_code\"] = main_code\n",
    "    return_data[\"meta_parameters\"] = {}\n",
    "    return_data[\"meta_parameters\"][\"config\"] = config\n",
    "    return_data[\"meta_parameters\"][\"join\"] = join\n",
    "    return_data[\"convergence_parameters\"] = convergence_parameters\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    return_data[\"run_time\"] = {}\n",
    "    return_data[\"run_time\"][\"start\"] = start\n",
    "    return_data[\"run_time\"][\"stop\"] = stop\n",
    "    return_data[\"run_time\"][\"run_time\"] = stop - start\n",
    "    \n",
    "    return return_data\n",
    "               \n",
    "               \n",
    "def initialise_lmform(\n",
    "    data_list,\n",
    "    config,\n",
    "    join,\n",
    "    transfer\n",
    "):\n",
    "\n",
    "    main_code = {}\n",
    "    main_code[\"code\"] = {}\n",
    "    main_code[\"encode\"] = {}\n",
    "\n",
    "    main_parameters = {}\n",
    "    main_parameters[\"beta\"] = {}\n",
    "    main_parameters[\"intercept\"] = {}\n",
    "    \n",
    "    for i in range(len(join[\"complete\"][\"data_list\"])):\n",
    "        main_code[\"code\"][join[\"complete\"][\"code\"][i]] = []\n",
    "        main_code[\"encode\"][join[\"complete\"][\"code\"][i]] = []\n",
    "\n",
    "        main_parameters[\"beta\"][join[\"complete\"][\"beta\"][i]] = []\n",
    "        main_parameters[\"intercept\"][join[\"complete\"][\"data_list\"][i]] = []\n",
    "    \n",
    "\n",
    "    for i in range(len(join[\"complete\"][\"data_list\"])):\n",
    "\n",
    "        if main_parameters[\"beta\"][join[\"complete\"][\"beta\"][i]] == []:\n",
    "            if not len(transfer[\"main_parameters\"][\"beta\"][join[\"complete\"][\"beta\"][i]]) == 0:\n",
    "                main_parameters[\"beta\"][join[\"complete\"][\"beta\"][i]] = transfer[\"main_parameters\"][\"beta\"][join[\"complete\"][\"beta\"][i]]\n",
    "            else:\n",
    "                main_parameters[\"beta\"][join[\"complete\"][\"beta\"][i]] = initialise_parameters_lmform(x = data_list[join[\"complete\"][\"data_list\"][i]], dim_main = config[\"j_dim\"], seed_main = 1, type_main = config[\"init\"][\"beta\"]).T\n",
    "\n",
    "        if main_code[\"code\"][join[\"complete\"][\"encode\"][i]] == []:\n",
    "            if not len(transfer[\"main_code\"][\"encode\"][join[\"complete\"][\"encode\"][i]]) == 0:\n",
    "                main_code[\"encode\"][join[\"complete\"][\"code\"][i]] = transfer[\"main_code\"][\"encode\"][join[\"complete\"][\"code\"][i]]\n",
    "            else:\n",
    "                main_code[\"encode\"][join[\"complete\"][\"code\"][i]] = data_list[join[\"complete\"][\"data_list\"][i]]@main_parameters[\"beta\"][join[\"complete\"][\"beta\"][i]]\n",
    "\n",
    "        if main_code[\"code\"][join[\"complete\"][\"code\"][i]] == []:\n",
    "            if not len(transfer[\"main_code\"][\"code\"][join[\"complete\"][\"code\"][i]]) == 0:\n",
    "                main_code[\"code\"][join[\"complete\"][\"code\"][i]] = transfer[\"main_code\"][\"code\"][join[\"complete\"][\"code\"][i]]\n",
    "            else:\n",
    "                main_code[\"code\"][join[\"complete\"][\"code\"][i]] = data_list[join[\"complete\"][\"data_list\"][i]]@torch.linalg.pinv((main_parameters[\"beta\"][join[\"complete\"][\"beta\"][i]]).T)\n",
    "\n",
    "        if main_parameters[\"intercept\"][join[\"complete\"][\"data_list\"][i]] == []:\n",
    "            if not len(transfer[\"main_parameters\"][\"intercept\"][join[\"complete\"][\"data_list\"][i]]) == 0:\n",
    "                main_parameters[\"intercept\"][join[\"complete\"][\"data_list\"][i]] = transfer[\"main_parameters\"][\"intercept\"][join[\"complete\"][\"data_list\"][i]]\n",
    "            else:\n",
    "                main_parameters[\"intercept\"][join[\"complete\"][\"data_list\"][i]] = torch.mean(data_list[join[\"complete\"][\"data_list\"][i]] - main_code[\"code\"][join[\"complete\"][\"code\"][i]]@(main_parameters[\"beta\"][join[\"complete\"][\"beta\"][i]].T),0)\n",
    "        \n",
    "    return main_parameters, main_code\n",
    "               \n",
    "               \n",
    "               \n",
    "def initialise_parameters_lmform(\n",
    "                            x,\n",
    "                            dim_main, \n",
    "                            seed_main,\n",
    "                            type_main):\n",
    "    if type_main == \"SVD\":\n",
    "        svd = TruncatedSVD(n_components=dim_main, n_iter=2, random_state=seed_main)\n",
    "        return svd.fit(x).components_\n",
    "\n",
    "    \n",
    "    if type_main == \"rand\":\n",
    "        rand_data = np.random.randn(dim_main,x.shape[1])\n",
    "        return rand_data\n",
    "    \n",
    "    \n",
    "               \n",
    "def update_set_lmform(x,main_parameters,main_code,config,fix):\n",
    "\n",
    "    if not fix[\"code\"]:\n",
    "        main_code[\"code\"] = (x - main_parameters[\"intercept\"])@torch.linalg.pinv(main_parameters[\"beta\"].T)\n",
    "               \n",
    "    if not fix[\"beta\"]:\n",
    "        main_parameters[\"beta\"] = (torch.linalg.pinv(main_code[\"code\"])@(x - main_parameters[\"intercept\"])).T\n",
    "               \n",
    "    if not fix[\"intercept\"]:\n",
    "        main_parameters[\"intercept\"] = torch.mean(x - (main_code[\"code\"])@(main_parameters[\"beta\"]).T,0)\n",
    "    \n",
    "    if not fix[\"encode\"]:\n",
    "        main_code[\"encode\"] = (x - main_parameters[\"intercept\"])@(main_parameters[\"beta\"])\n",
    "\n",
    "    return main_parameters, main_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85389c8a-ccab-4598-92e4-59826a46c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ad3645-3bb9-4389-a8de-cbcfc7597879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb2a6e4-b113-4aca-b2b0-eb0784562c52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "config[\"i_dim\"] = 1\n",
    "config[\"init\"] =  {}\n",
    "config[\"init\"][\"alpha\"] = \"SVD\"\n",
    "config[\"init\"][\"beta\"] = \"SVD\"\n",
    "config[\"max_iter\"] =  15\n",
    "config[\"verbose\"] =  False\n",
    "config[\"seed\"] =  1\n",
    "config[\"tol\"] =  1e-5\n",
    "       \n",
    "join = {}\n",
    "join[\"complete\"] = {}\n",
    "join[\"complete\"][\"data_list\"] = [\"data_1\"]\n",
    "join[\"complete\"][\"alpha\"] = [\"data_1\"]\n",
    "join[\"complete\"][\"beta\"] = [\"data_1\"]\n",
    "join[\"complete\"][\"code\"] = [\"data_1\"]\n",
    "join[\"complete\"][\"encode\"] = [\"data_1\"]\n",
    "\n",
    "transfer = {}\n",
    "transfer[\"fix\"] = {}\n",
    "transfer[\"fix\"][\"alpha\"] = False\n",
    "transfer[\"fix\"][\"beta\"] = False\n",
    "transfer[\"fix\"][\"code\"] = False\n",
    "transfer[\"fix\"][\"intercept\"] = False\n",
    "transfer[\"fix\"][\"encode\"] = False\n",
    "\n",
    "transfer[\"main_code\"] = {}\n",
    "transfer[\"main_code\"][\"code\"] = {}\n",
    "transfer[\"main_code\"][\"encode\"] = {}\n",
    "\n",
    "transfer[\"main_parameters\"] = {}\n",
    "transfer[\"main_parameters\"][\"alpha\"] = {}\n",
    "transfer[\"main_parameters\"][\"beta\"] = {}\n",
    "transfer[\"main_parameters\"][\"intercept\"] = {}\n",
    "\n",
    "\n",
    "for i in range(len(join[\"complete\"][\"data_list\"])):\n",
    "    transfer[\"main_code\"][\"code\"][join[\"complete\"][\"code\"][i]] = []\n",
    "    transfer[\"main_code\"][\"encode\"][join[\"complete\"][\"encode\"][i]] = []\n",
    "\n",
    "    transfer[\"main_parameters\"][\"alpha\"][join[\"complete\"][\"alpha\"][i]] = []\n",
    "    transfer[\"main_parameters\"][\"beta\"][join[\"complete\"][\"beta\"][i]] = []\n",
    "    transfer[\"main_parameters\"][\"intercept\"][join[\"complete\"][\"data_list\"][i]] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03f56ab8-f985-4178-a461-3e3dc2419e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "batch_size = 32\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48dad4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "class summary_layer(nn.Module):\n",
    "    def __init__(self, J_dim, common_dim):\n",
    "        super(summary_layer, self).__init__()\n",
    "\n",
    "        self.code_func_c = nn.Linear(J_dim,common_dim)\n",
    "        self.code_func_I = nn.Linear(common_dim,common_dim)\n",
    "\n",
    "        self.beta_I = torch.eye(J_dim,J_dim)\n",
    "        self.beta_func1 = nn.Linear(J_dim,common_dim)\n",
    "        \n",
    "    def forward(self, x, init, gradient):\n",
    "\n",
    "        B,D = x.shape\n",
    "\n",
    "        beta = self.beta_func1(self.beta_I)\n",
    "        code = (self.code_func_I((self.code_func_c(x))))\n",
    "        \n",
    "        if init:\n",
    "        \n",
    "            data_list = {}\n",
    "            data_list[\"data_1\"] = x\n",
    "\n",
    "            if gradient:\n",
    "                transfer[\"main_parameters\"][\"beta\"][\"data_1\"] = beta\n",
    "                transfer[\"main_code\"][\"encode\"][\"data_1\"] = transfer[\"main_code\"][\"code\"][\"data_1\"] = code\n",
    "\n",
    "                transfer[\"fix\"][\"beta\"] = False\n",
    "                transfer[\"fix\"][\"code\"] = False\n",
    "                transfer[\"fix\"][\"encode\"] = False\n",
    "            else:\n",
    "                transfer[\"main_parameters\"][\"beta\"][\"data_1\"] = torch.randn(beta.shape)\n",
    "                transfer[\"main_code\"][\"encode\"][\"data_1\"] = transfer[\"main_code\"][\"code\"][\"data_1\"] = torch.randn(code.shape)\n",
    "\n",
    "                transfer[\"fix\"][\"beta\"] = False\n",
    "                transfer[\"fix\"][\"code\"] = False\n",
    "                transfer[\"fix\"][\"encode\"] = False\n",
    "\n",
    "                \n",
    "            config[\"j_dim\"] = beta.shape[1]\n",
    "\n",
    "            lmform_model = lmform(\n",
    "                data_list = data_list,\n",
    "                config = config,\n",
    "                join = join,\n",
    "                transfer = transfer\n",
    "            )\n",
    "\n",
    "            beta = lmform_model[\"main_parameters\"][\"beta\"][\"data_1\"]\n",
    "\n",
    "        x = x@beta\n",
    "        return x\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    '''\n",
    "    VGG model \n",
    "    '''\n",
    "    def __init__(self, features):\n",
    "        super(VGG, self).__init__()\n",
    "\n",
    "        self.features = features\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Dropout(),\n",
    "        #     nn.Linear(512, 512),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Dropout(),\n",
    "        #     nn.Linear(512, 512),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Linear(512, 10),\n",
    "        # )\n",
    "        self.classifier = summary_layer(512,1000)\n",
    "        self.output = summary_layer(1000,10)\n",
    "\n",
    "        \n",
    "         # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x,False,True)\n",
    "        x = self.output(x,False,True)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
    "          512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def vgg11():\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\")\"\"\"\n",
    "    return VGG(make_layers(cfg['A']))\n",
    "\n",
    "\n",
    "def vgg11_bn():\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['A'], batch_norm=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f089f56-09ee-4963-a482-b6818b9a0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"j_dim\"] = 10\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "net = vgg11()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.001, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01ca8aa4-139d-45f2-b6ca-3cdea24d2de9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1563] loss: 76.1479275118\n",
      "660.7372841835022\n",
      "[2,  1563] loss: 20.6181715673\n",
      "2716.354638338089\n",
      "[3,  1563] loss: 15.7575139653\n",
      "4795.04381775856\n",
      "[4,  1563] loss: 13.0960033145\n",
      "7003.925266742706\n",
      "[5,  1563] loss: 11.3457923926\n",
      "9946.449864387512\n",
      "Finished Training\n",
      "9946.450338840485\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    cousnt=0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        count=i\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "            \n",
    "    print(f'[{epoch + 1}, {count + 1:5d}] loss: {running_loss / 99:.10f}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "    end = time.time()\n",
    "    print(end - start)  \n",
    "    net.init = False\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e2cde50-6967-4221-bc0c-40f7ad8c0909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 68.94 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5d16fba-262b-4af4-a7fb-f0fb2cfb7ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 85.4 %\n",
      "Accuracy for class: car   is 76.4 %\n",
      "Accuracy for class: bird  is 75.8 %\n",
      "Accuracy for class: cat   is 35.3 %\n",
      "Accuracy for class: deer  is 47.0 %\n",
      "Accuracy for class: dog   is 54.2 %\n",
      "Accuracy for class: frog  is 82.4 %\n",
      "Accuracy for class: horse is 81.9 %\n",
      "Accuracy for class: ship  is 80.4 %\n",
      "Accuracy for class: truck is 70.6 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf122cc5-2014-4349-945f-10f7e928239c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9be247-9465-4a64-9c0a-7a8dde329089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd5410c-687c-4791-81d0-200ca57f1901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
